{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fa63ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fcfdef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.9.1+cu126\n"
     ]
    }
   ],
   "source": [
    "print(\"torch:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c904a0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA version: 12.6\n",
      "GPU count: 1\n",
      "GPU name: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"GPU count:\", torch.cuda.device_count())\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90fff3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d88383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "522462d8",
   "metadata": {},
   "source": [
    "# tabluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3afbdce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(430, 24)\n",
      "  sample_id  anchor_age  hadm_count  icustay_count  transfer_count  \\\n",
      "0  s_000000        52.0         1.0            1.0             6.0   \n",
      "1  s_000256        69.0         1.0            1.0             4.0   \n",
      "2  s_000512        68.0         1.0            1.0             6.0   \n",
      "3  s_000768        87.0         1.0            1.0             2.0   \n",
      "4  s_001024        56.0         1.0            1.0            10.0   \n",
      "\n",
      "   presc_count  presc_unique_drug  proc_count  proc_unique_icd  icu_los_hours  \\\n",
      "0         24.0               17.0         0.0              0.0       9.846389   \n",
      "1         87.0               52.0         0.0              0.0      17.021111   \n",
      "2        158.0               71.0         0.0              0.0      20.616112   \n",
      "3         78.0               52.0         0.0              0.0     116.258057   \n",
      "4        298.0               72.0         0.0              0.0     123.025833   \n",
      "\n",
      "   ...  insurance  language  marital_status  first_careunit  \\\n",
      "0  ...          1         1               1               1   \n",
      "1  ...          2         1               2               2   \n",
      "2  ...          2         1               2               1   \n",
      "3  ...          2         1               2               2   \n",
      "4  ...          3         1               3               1   \n",
      "\n",
      "   last_transfer_eventtype  last_transfer_careunit  top_drug_type  top_route  \\\n",
      "0                        1                       0              1          1   \n",
      "1                        1                       0              1          2   \n",
      "2                        1                       0              1          2   \n",
      "3                        1                       0              1          2   \n",
      "4                        1                       0              1          2   \n",
      "\n",
      "   top_drug  top_icd_code  \n",
      "0         1             0  \n",
      "1         2             0  \n",
      "2         3             0  \n",
      "3         4             0  \n",
      "4         5             0  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_tab_bucket_as_df(root, bucket_id=0, decode_cats=False):\n",
    "    bucket_dir = os.path.join(root, \"tab_tensor_v1\", f\"bucket_{bucket_id:03d}\")\n",
    "    schema_fp = os.path.join(bucket_dir, \"schema.json\")\n",
    "    with open(schema_fp, \"r\", encoding=\"utf-8\") as f:\n",
    "        schema = json.load(f)\n",
    "\n",
    "    sample_id = np.load(os.path.join(bucket_dir, \"sample_id.npy\"), allow_pickle=True)\n",
    "    X_num = np.load(os.path.join(bucket_dir, \"numeric.npy\"))  # float32\n",
    "    num_cols = schema[\"num_cols\"]\n",
    "    cat_cols = schema[\"cat_cols\"]\n",
    "\n",
    "    df = pd.DataFrame(X_num, columns=num_cols)\n",
    "    df.insert(0, \"sample_id\", sample_id.astype(str))\n",
    "\n",
    "    # 读入所有 cat 列（idx）\n",
    "    for i, c in enumerate(cat_cols):\n",
    "        fp = os.path.join(bucket_dir, f\"cat_{i:02d}_{c}.npy\")\n",
    "        if not os.path.exists(fp):\n",
    "            # 容错：目录里可能缺某个列\n",
    "            df[c] = 0\n",
    "            continue\n",
    "        df[c] = np.load(fp).astype(np.int64)\n",
    "\n",
    "    if decode_cats:\n",
    "        # vocabs.json 在 tab_tensor_v1 根目录\n",
    "        vocabs_fp = os.path.join(root, \"tab_tensor_v1\", \"vocabs.json\")\n",
    "        with open(vocabs_fp, \"r\", encoding=\"utf-8\") as f:\n",
    "            vocabs = json.load(f)\n",
    "\n",
    "        # token->idx 反转成 idx->token\n",
    "        inv = {}\n",
    "        for c in cat_cols:\n",
    "            v = vocabs.get(c, {})\n",
    "            inv[c] = {int(idx): tok for tok, idx in v.items()}\n",
    "\n",
    "        for c in cat_cols:\n",
    "            df[c] = df[c].map(lambda x: inv[c].get(int(x), \"__UNK__\"))\n",
    "\n",
    "    return df, schema\n",
    "\n",
    "# 用法\n",
    "ROOT = r\"E:/NUS/data/perdata/train_text_all_samples\"\n",
    "df0, schema0 = load_tab_bucket_as_df(ROOT, bucket_id=0, decode_cats=False)\n",
    "print(df0.shape)\n",
    "print(df0.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a356ac62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\anaconda\\envs\\grmenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tab_embed: torch.Size([430, 233]) loss: 1.5567512512207031\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "ROOT = r\"E:/NUS/data/perdata/train_text_all_samples\"\n",
    "bucket = 0\n",
    "bucket_dir = os.path.join(ROOT, \"tab_tensor_v1\", f\"bucket_{bucket:03d}\")\n",
    "\n",
    "with open(os.path.join(bucket_dir, \"schema.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    schema = json.load(f)\n",
    "\n",
    "# load\n",
    "X_num = np.load(os.path.join(bucket_dir, \"numeric.npy\")).astype(np.float32)\n",
    "num_cols = schema[\"num_cols\"]\n",
    "cat_cols = schema[\"cat_cols\"]\n",
    "\n",
    "cat_list = []\n",
    "for i, c in enumerate(cat_cols):\n",
    "    cat_path = os.path.join(bucket_dir, f\"cat_{i:02d}_{c}.npy\")\n",
    "    cat_list.append(np.load(cat_path).astype(np.int64))\n",
    "\n",
    "# to torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "x_num = torch.from_numpy(X_num).to(device)\n",
    "\n",
    "cat_tensors = [torch.from_numpy(a).to(device) for a in cat_list]\n",
    "\n",
    "# (可选) 标准化：这里先用桶内统计演示，真正训练建议用全训练集统计\n",
    "mean = x_num.mean(dim=0, keepdim=True)\n",
    "std = x_num.std(dim=0, keepdim=True).clamp_min(1e-6)\n",
    "x_num_std = (x_num - mean) / std\n",
    "\n",
    "# init model\n",
    "from data import TabularEncoder  # 你自己改成实际import\n",
    "model = TabularEncoder(\n",
    "    numeric_dim=len(num_cols),\n",
    "    categorical_cardinalities=schema[\"cat_cardinalities\"],\n",
    "    cat_embed_dim=16,\n",
    "    reg_weights={\"ent\": 0.0, \"lap\": 0.0, \"stein\": 0.0},\n",
    ").to(device)\n",
    "\n",
    "# forward\n",
    "tab_embed, loss = model(x_num_std, cat_tensors)\n",
    "print(\"tab_embed:\", tab_embed.shape, \"loss:\", float(loss.detach().cpu()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c2eea85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\anaconda\\envs\\grmenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tab_embed: torch.Size([430, 352]) loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# cat+mlp\n",
    "ROOT = r\"E:/NUS/data/perdata/train_text_all_samples\"\n",
    "bucket = 0\n",
    "bucket_dir = os.path.join(ROOT, \"tab_tensor_v1\", f\"bucket_{bucket:03d}\")\n",
    "\n",
    "with open(os.path.join(bucket_dir, \"schema.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    schema = json.load(f)\n",
    "\n",
    "# load\n",
    "X_num = np.load(os.path.join(bucket_dir, \"numeric.npy\")).astype(np.float32)\n",
    "num_cols = schema[\"num_cols\"]\n",
    "cat_cols = schema[\"cat_cols\"]\n",
    "\n",
    "cat_list = []\n",
    "for i, c in enumerate(cat_cols):\n",
    "    cat_path = os.path.join(bucket_dir, f\"cat_{i:02d}_{c}.npy\")\n",
    "    cat_list.append(np.load(cat_path).astype(np.int64))\n",
    "\n",
    "# to torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "x_num = torch.from_numpy(X_num).to(device)\n",
    "\n",
    "cat_tensors = [torch.from_numpy(a).to(device) for a in cat_list]\n",
    "\n",
    "# (可选) 标准化：这里先用桶内统计演示，真正训练建议用全训练集统计\n",
    "mean = x_num.mean(dim=0, keepdim=True)\n",
    "std = x_num.std(dim=0, keepdim=True).clamp_min(1e-6)\n",
    "x_num_std = (x_num - mean) / std\n",
    "\n",
    "# init model\n",
    "from data import TabularEncoderCMLP  # 你自己改成实际import\n",
    "model = TabularEncoderCMLP(\n",
    "    numeric_dim=len(num_cols),\n",
    "    categorical_cardinalities=schema[\"cat_cardinalities\"],\n",
    "    cat_embed_dim=16,\n",
    "    reg_weights={\"ent\": 0.0, \"lap\": 0.0, \"stein\": 0.0},\n",
    ").to(device)\n",
    "\n",
    "# forward\n",
    "tab_embed, loss = model(x_num_std, cat_tensors)\n",
    "print(\"tab_embed:\", tab_embed.shape, \"loss:\", float(loss.detach().cpu()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
